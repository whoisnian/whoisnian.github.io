---
layout: post
title: 整理httpd日志中的信息
categories: Server
---

> 因为没有使用Google Analytics一类的流量统计服务，所以博客的具体访问情况对于我是未知的，突然想去了解一下，于是就想到了可以分析httpd日志中的信息。

<!-- more -->

## 准备
* 从服务器上下载日志。  
  直接sftp到指定的日志文件夹中把`whoisnian.com-access_log`下载下来即可。  
* 选择要使用的工具。  
  想顺便熟悉一下SHELL操作，就直接用Linux的各种命令来处理了。

## 目标  
先看看日志里有什么：  
`10.10.10.10 - - [08/May/2019:17:17:33 +0800] "GET / HTTP/1.1" 200 9584`  
我的日志里每一行都是这样的格式，在[Apache官方文档](https://httpd.apache.org/docs/current/mod/mod_log_config.html)中被叫做`Common Log Format (CLF)`，具体含义为：  
`远端主机地址 远端登录名 远程用户名 时间 请求的第一行 状态码 传送的不包含HTTP头的字节数`  
也就是说，从日志中可以获取到的有用信息包括访问者的IP，访问时间，请求的具体网址，请求用的协议，服务器响应码。所以统计以下几点是可行的：  
* 单个IP的访问次数排行
* 具体的网页访问量排行
* 访问者IP分布

可惜之前服务器的一次滚挂，导致下载到的日志只有2018年9月份之后的，猜测最终得到的结果会比较寒酸。😭  

## 筛选
直接打开日志文件，约十四万行，但很明显，里面有许多无效请求。例如：  
* `61.176.222.170 - - [20/Sep/2018:04:49:42 +0800] "GET http://47.99.121.32:39169/Ip/Up?Ip=45.77.221.110&Port=80&Check=30&Order=61.176.222.170 HTTP/1.1" 404 1010`  
* `193.112.137.18 - - [20/Sep/2018:06:17:47 +0800] "POST /cainiao.php HTTP/1.1" 404 16`  
* `221.231.6.240 - - [26/Sep/2018:03:32:52 +0800] "GET /Web/FCKeditor/fckeditor.js HTTP/1.1" 404 1119`  
* `122.114.90.3 - - [26/Sep/2018:21:59:09 +0800] "POST //plus/moon.php HTTP/1.1" 301 243`  
* `173.212.192.252 - - [27/Sep/2018:10:49:11 +0800] "GET /scripts/setup.php HTTP/1.1" 301 247`  

明显是各种自动化扫描工具的请求，试了一下`cat whoisnian.com-access_log | grep '\.php' | wc -l`，emmmmmm，36398行带`.php`的，推测扫描工具的访问占了日志三分之一以上。  

于是根据我的链接格式，我只保留了对博客文章的访问且服务器返回非404状态码的日志，即：  
`cat whoisnian.com-access_log | grep -oP '.* - - .* \+0800] "GET /[0-9]{4}/[0-9]{2}/[0-9]{2}/.*" (?!404).*' > log1`  
好嘛，原来十多万行的日志就剩7625行了，太真实了。  

先就这样进行一次初步筛选吧，理想情况下还可以只保留同时请求了css文件和博客文章的日志记录，应该可以进一步排除一部分爬虫。  

## 统计
* 单个IP的访问次数排行：  
  `cat log1 | awk '{ print $1 }' | sort | uniq -idc | sort -k1nr | head -n 15`  
  将文件log1的内容每行只保留IP，排序合并，再按合并得到的次数降序，输出前15行，结果为：  
  
  次数| IP地址
  ----|----
  221 | 5.45.207.10
  204 | 23.100.232.233
  169 | 66.249.70.30
  161 | 66.249.70.28
  160 | 66.249.66.81
  154 | 66.249.70.3
  121 | 66.249.66.80
  111 | 66.249.66.79
  108 | 111.202.100.130
  83 | 78.46.161.81
  76 | 159.65.177.231
  61 | 66.249.66.62
  60 | 5.45.207.44
  59 | 66.249.66.60
  59 | 66.249.66.83

  emmmmmm，`nslookup 5.45.207.10`可以看到`name = 5-45-207-10.spider.yandex.com.`，同理，`66.249.*.*`是google的，`111.202.100.130`是sougou的，看起来变成爬虫爬取次数排序了。。。

* 具体的网页访问量排行：  
  `cat log1 | awk '{ print $1,$7 }' | sed 's/\/$//g' | sort | uniq | awk '{ print $2 }' | sort | uniq -idc | sort -k1nr | sed 's@+@ @g;s@%@\\x@g' | xargs -0 printf "%b" | head -n 15`  
  将文件log1的内容每行只保留IP和访问的链接，排序合并，即一个IP访问一篇文章只计算一次，再将结果只保留文章链接，排序合并，最后按合并得到的次数降序，输出前15行，结果为：  

  次数| 网页地址
  ----|----
  316 | /2018/06/21/给服务器设置动态motd效果
  252 | /2017/07/23/ArchLinux安装配置WineQQ
  246 | /2017/12/27/apache反向代理google
  235 | /2018/02/09/template-is-undefined
  229 | /2018/03/10/honor-8-from-emui-5-to-lineage-os-14.1
  217 | /2017/08/15/网易云音乐白屏
  195 | /2017/11/11/i3-WM
  184 | /2018/06/13/wps-office使用记录
  182 | /2017/04/07/ArchLinux使用记录
  165 | /2018/11/18/通过酷Q小号转发信息
  140 | /2018/08/23/在u盘上安装lfs
  133 | /2017/04/02/ArchLinux-Installation-Guide
  124 | /2017/10/26/Raspberry图形界面下鼠标移动缓慢
  120 | /2017/04/15/raspberry实现简单的dns劫持
  120 | /2017/06/01/Vultr搭建SS服务

* 访问者IP分布

未完待续。。。
